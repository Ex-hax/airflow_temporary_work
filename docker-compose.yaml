services:
  airflow:
    build:
      context: .
      dockerfile: Dockerfile
    ports:
      - "5000:5000"
    volumes:
      - ./dags:/opt/airflow/dags
      - ./plugins:/opt/airflow/plugins
      - ./init-scripts/airflow:/opt/airflow/init-scripts
    environment:
      - AIRFLOW__WEBSERVER__WEB_SERVER_PORT=5000
      - AIRFLOW__CORE__SQL_ALCHEMY_CONN=postgresql+psycopg2://postgres:1234@postgres:5432/airflow_db
      - AIRFLOW__WEBSERVER__SECRET_KEY=samesecret1234
      - AIRFLOW__CORE__DAGS_FOLDER=/opt/airflow/dags
      - AIRFLOW__CORE__PLUGINS_FOLDER=/opt/airflow/plugins
      - AIRFLOW__SMTP__SMTP_HOST=smtp.gmail.com
      - AIRFLOW__SMTP__SMTP_USER=watchara.c.lee@gmail.com
      - AIRFLOW__SMTP_SMTP_MAIL_FROM=watchara.c.lee@gmail.com
      - AIRFLOW__SMTP__SMTP_PASSWORD=benjjtufjbugqkhw
      - AIRFLOW__SMTP__SMTP_PORT=465
    depends_on:
      postgres:
        condition: service_healthy
    command: >
      bash -c "
        /bin/bash /opt/airflow/init-scripts/init_database.sh
        /bin/bash /opt/airflow/init-scripts/create_admin_user.sh
        /bin/bash /opt/airflow/init-scripts/start_webserver.sh
    
        # # Check if the webserver is up before creating the admin user
        # while ! curl -s http://localhost:5000/health | grep -q 'healthy'; do
        #   echo '>>>>>>>>>>>>>>>>>>>>>>>> Waiting for Airflow webserver...'
        #   sleep 2
        # done
        
        wait -n

        tail -f /dev/null
      "

  scheduler:
    build:
      context: .
      dockerfile: Dockerfile
    volumes:
      - ./dags:/opt/airflow/dags
      - ./plugins:/opt/airflow/plugins
    environment:
      - AIRFLOW__CORE__SQL_ALCHEMY_CONN=postgresql+psycopg2://postgres:1234@postgres:5432/airflow_db
      - AIRFLOW__WEBSERVER__SECRET_KEY=samesecret1234
      - AIRFLOW__CORE__DAGS_FOLDER=/opt/airflow/dags
      - AIRFLOW__CORE__PLUGINS_FOLDER=/opt/airflow/plugins
      - AIRFLOW__SMTP__SMTP_HOST=smtp.gmail.com
      - AIRFLOW__SMTP__SMTP_USER=watchara.c.lee@gmail.com
      - AIRFLOW__SMTP_SMTP_MAIL_FROM=watchara.c.lee@gmail.com
      - AIRFLOW__SMTP__SMTP_PASSWORD=benjjtufjbugqkhw
      - AIRFLOW__SMTP__SMTP_PORT=465
    depends_on:
      postgres:
        condition: service_healthy
    command: ["airflow", "scheduler"]

  spark:
    image: bitnami/spark:latest
    ports:
      - "8080:8080"  # Spark web UI
    environment:
      - SPARK_MODE=master
      - ALLOW_EMPTY_PASSWORD=yes
    volumes:
      - ./spark/pyspark:/opt/bitnami/spark/work/pyspark
      - ./spark/config:/opt/bitnami/spark/work/config

  jupyter:
    image: jupyter/base-notebook
    ports:
      - "8888:8888"
    volumes:
      - ./dags:/home/jovyan/work/dags
      - ./spark/pyspark:/home/jovyan/work/pyspark
      - ./spark/config:/home/jovyan/work/config
    environment:
      JUPYTER_ENABLE_LAB: "yes"
    command: "start-notebook.sh --NotebookApp.token=''"

  postgres:
    image: postgres:13
    container_name: postgres
    environment:
      POSTGRES_USER: postgres
      POSTGRES_PASSWORD: 1234
      POSTGRES_DB: airflow_db
    ports:
      - "5432:5432"  # Mapping local port 5433 to container port 5432
    volumes:
      - postgres_data:/var/lib/postgresql/data
      - ./init-scripts/postgres/airflow:/docker-entrypoint-initdb.d
    healthcheck:
      test: ["CMD-SHELL", "pg_isready -U postgres"]
      interval: 10s
      timeout: 5s
      retries: 5

  mock_postgres:
    image: postgres:13
    container_name: mock_postgres
    environment:
      POSTGRES_USER: postgres
      POSTGRES_PASSWORD: 1234
      POSTGRES_DB: mock_db
      PGPORT: 5433
    ports:
      - "5433:5433"  # Mapping local port 5433 to container port 5432
    volumes:
      - mock_postgres_data:/var/lib/postgresql/data
      - ./init-scripts/postgres/postgres:/docker-entrypoint-initdb.d

  ubuntu:
    build:
      context: .
      dockerfile: Dockerfile.ubuntu
    container_name: ubuntu_port_tunnel
    tty: true   # Allows interactive sessions with the container
    stdin_open: true  # Keeps the container open for interaction
    volumes:
      - ./ngrok_config:/root/.config/ngrok
    command: > 
      bash -c "
        ngrok start --all
      "
    network_mode: "host"

volumes:
  postgres_data:
  mock_postgres_data:


  # zookeeper:
  #   image: 'bitnami/zookeeper:latest'
  #   ports:
  #     - "2181:2181"
  #   environment:
  #     - ALLOW_ANONYMOUS_LOGIN=yes

  # kafka:
  #   image: 'bitnami/kafka:latest'
  #   ports:
  #     - "9092:9092"
  #   environment:
  #     - KAFKA_CFG_ZOOKEEPER_CONNECT=zookeeper:2181
  #     - KAFKA_CFG_LISTENERS=PLAINTEXT://:9092
  #     - KAFKA_CFG_ADVERTISED_LISTENERS=PLAINTEXT://localhost:9092
  #     - KAFKA_CFG_LISTENER_SECURITY_PROTOCOL_MAP=PLAINTEXT:PLAINTEXT
  #     - KAFKA_CFG_BROKER_ID=1
  #     - KAFKA_CFG_AUTO_CREATE_TOPICS_ENABLE=true
  #     - ALLOW_PLAINTEXT_LISTENER=yes
  #   depends_on:
  #     - zookeeper
